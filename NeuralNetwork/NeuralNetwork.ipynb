{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network():\n",
    "    def __init__(self, x, y, layers):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.layers = layers\n",
    "        self.w = [np.random.randn(self.layers[i], self.layers[i-1]) for i in range(1, len(self.layers))]\n",
    "        self.b = [np.random.randn(self.layers[i],1) for i in range(1, len(self.layers))]\n",
    "        \n",
    "        \n",
    "    def sigmoid(self, layer):\n",
    "        return [1/(1 + np.exp(layer[i])) for i in range(len(layer))]\n",
    "    \n",
    "    def softmax(self, layer):\n",
    "        ret_vector = []\n",
    "        sum_of_vector = 0\n",
    "        for i in range(len(layer)):\n",
    "            sum_of_vector += exp(layer[i])\n",
    "        \n",
    "        for j in range(len(layer)):\n",
    "            ret_vector.append(exp(layer[j]) / sum_of_vector)\n",
    "        \n",
    "        return ret_vector\n",
    "    \n",
    "    def pre_act(self, x, w, b):\n",
    "        return np.dot(w, x) + b.flatten()\n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        h = [x.copy()]\n",
    "        for i in range(len(layers) - 1):\n",
    "            a = self.pre_act(x, self.w[i], self.b[i])\n",
    "            if i != len(self.layers) - 2:\n",
    "                h.append(self.sigmoid(a))\n",
    "            else:\n",
    "                h.append(self.softmax(a))\n",
    "        return np.array(h)\n",
    "    \n",
    "    def back_prop(self, h, y):\n",
    "        numbla_a = list(h[-1] - np.array(y))\n",
    "        numbla_thetta_W = []\n",
    "        numbla_thetta_b = []\n",
    "\n",
    "        for k in range(len(self.layers)-1, 0, -1):\n",
    "            numbla_W = list(np.multiply(numbla_a, np.transpose(h[k])))\n",
    "            numbla_b = list(numbla_a)\n",
    "            \n",
    "            for _ in range(self.layers[0] - self.layers[k]):\n",
    "                numbla_W.append(0)\n",
    "                numbla_b.append(0)\n",
    "            \n",
    "                \n",
    "            numbla_thetta_W.append(np.array(numbla_W))\n",
    "            numbla_thetta_b.append(np.array(numbla_b))\n",
    "            \n",
    "            numbla_h = np.dot(self.w[k-1].T, np.array(numbla_a))\n",
    "            numbla_a = np.multiply(np.transpose(numbla_h), [h[k-1][m] * (1 - h[k-1][m]) for m in range(len(h[k-1]))])\n",
    "        return numbla_thetta_W, numbla_thetta_b\n",
    "    \n",
    "    def gradient_descent(self, etta=0.01):\n",
    "        for i in range(len(self.x)):\n",
    "            store = self.feedforward(self.x[i]) \n",
    "            numbla_thetta_W, numbla_thetta_b = self.back_prop(store, self.y[i])\n",
    "            for j in range(len(self.w)-1, -1, -1):\n",
    "                self.w[j] -= etta * numbla_thetta_W[j]\n",
    "                sub_b = (etta * numbla_thetta_b[j])[:self.layers[j+1]]\n",
    "                self.b[j] = self.b[j].T - sub_b\n",
    "        return self.w, self.b\n",
    "    \n",
    "    def neural(self):\n",
    "        return self.back_prop(self.feedforward(self.x), self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 5.56522471e-01,  1.14474834e+00, -9.29840272e-01,\n",
      "        -1.00654644e+00,  4.28176990e-01],\n",
      "       [-6.36368836e-02,  8.34461390e-01,  4.36607860e-01,\n",
      "         7.73936688e-01,  3.89618737e-01],\n",
      "       [-2.88407456e+00,  1.27549158e+00, -6.85806463e-01,\n",
      "        -1.14369861e+00, -9.17297001e-01],\n",
      "       [ 9.75761453e-01, -5.62820451e-01,  5.70092553e-01,\n",
      "        -1.68025497e+00,  8.51210818e-01],\n",
      "       [ 3.36566175e-01,  1.35901887e+00, -1.95221237e-03,\n",
      "        -3.85954115e-01, -5.25409553e-01]]), array([[-1.66749537, -1.89099805, -1.5983304 , -0.02344266,  1.23257487],\n",
      "       [ 0.33044047, -0.34998502,  0.10651779, -0.99334179,  0.58717616],\n",
      "       [-2.74753913, -0.44439854,  0.52624331, -0.99456745,  1.21152251]])]\n",
      "\n",
      "[array([[-0.18788017, -0.19788007, -0.17788027, -0.18788017, -0.18788017],\n",
      "       [-0.02839526, -0.03839516, -0.01839536, -0.02839526, -0.02839526],\n",
      "       [ 0.66599802,  0.65599812,  0.67599792,  0.66599802,  0.66599802],\n",
      "       [ 0.44337203,  0.43337213,  0.45337193,  0.44337203,  0.44337203],\n",
      "       [ 0.5047977 ,  0.4947978 ,  0.5147976 ,  0.5047977 ,  0.5047977 ]]), array([[ 0.54562459,  0.55172809,  0.55172809],\n",
      "       [ 1.46987831,  1.4759818 ,  1.4759818 ],\n",
      "       [-0.50487773, -0.49877424, -0.49877424]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-402-4ae21a19d35d>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(h)\n"
     ]
    }
   ],
   "source": [
    "x = [[1, 2, 3, 4, 5],[6, 7, 8, 9, 10]]\n",
    "y = [[1, 0, 0], [0, 0, 1]]\n",
    "layers = [5, 5, 3]\n",
    "NN = Neural_Network(x, y, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
